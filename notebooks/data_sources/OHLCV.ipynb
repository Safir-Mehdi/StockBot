{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d652ee",
   "metadata": {},
   "source": [
    "## ðŸ† Top 10 Tickers in the Dataset\n",
    "\n",
    "Below is a table showing the top 10 most frequently mentioned ticker symbols in the news dataset. These tickers represent some of the most actively discussed companies in the US capital markets between 2020 and 2024.\n",
    "\n",
    "| ðŸ¥‡ Rank | ðŸ’¹ Ticker Symbol |\n",
    "|---------|:----------------|\n",
    "| 1       | ðŸ AAPL         |\n",
    "| 2       | ðŸ’» MSFT         |\n",
    "| 3       | ðŸŒ GOOGL        |\n",
    "| 4       | ðŸ“¦ AMZN         |\n",
    "| 5       | ðŸ“± META         |\n",
    "| 6       | ðŸš— TSLA         |\n",
    "| 7       | ðŸ¤– NVDA         |\n",
    "| 8       | ðŸ¦ JPM          |\n",
    "| 9       | ðŸ’³ V            |\n",
    "| 10      | ðŸ¥ UNH          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5b5d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import yfinance\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3194edf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Upwork Projects\\\\Trading Bot\\\\StockBot'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('f:\\\\Upwork Projects\\\\Trading Bot\\\\StockBot')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91896f60",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ OHLCV (Open, High, Low, Close, Volume) Data Sourcing\n",
    "\n",
    "This section covers how we fetch and store historical OHLCV data for the top 10 most discussed US tickers using Yahoo Finance.\n",
    "\n",
    "- ðŸ¦ **Tickers:** AAPL, NVDA, META, TSLA, MSFT, GOOGL, AMZN, JPM, V, UNH\n",
    "- â³ **Time Range:** Last 4 years (hourly interval)\n",
    "- ðŸ’¾ **Data Location:** Saved in `data/raw/ohlcv_data/`\n",
    "- âš™ï¸ **Automation:** Output directory is created automatically if it doesn't exist\n",
    "- ðŸš¦ **Error Handling:** Notifies if data is missing or if an error occurs during download\n",
    "- ðŸ“Š **Purpose:** Enables downstream analysis, modeling, and backtesting for trading strategies\n",
    "\n",
    "âš ï¸ **Note:** Intraday data (e.g., 1h, 4h) is only available for the last 60â€“730 days due to Yahoo Finance limitations. For longer periods, use daily or weekly intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd71fbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Fetching historical OHLCV data for 10 tickers...\n",
      "â³ Fetching data for AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of AAPL in file path data/raw/ohlcv_data\\AAPL_1h.csv.\n",
      "\n",
      "â³ Fetching data for NVDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of NVDA in file path data/raw/ohlcv_data\\NVDA_1h.csv.\n",
      "\n",
      "â³ Fetching data for META\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of META in file path data/raw/ohlcv_data\\META_1h.csv.\n",
      "\n",
      "â³ Fetching data for TSLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of TSLA in file path data/raw/ohlcv_data\\TSLA_1h.csv.\n",
      "\n",
      "â³ Fetching data for MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of MSFT in file path data/raw/ohlcv_data\\MSFT_1h.csv.\n",
      "\n",
      "â³ Fetching data for GOOGL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of GOOGL in file path data/raw/ohlcv_data\\GOOGL_1h.csv.\n",
      "\n",
      "â³ Fetching data for AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of AMZN in file path data/raw/ohlcv_data\\AMZN_1h.csv.\n",
      "\n",
      "â³ Fetching data for JPM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of JPM in file path data/raw/ohlcv_data\\JPM_1h.csv.\n",
      "\n",
      "â³ Fetching data for V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of V in file path data/raw/ohlcv_data\\V_1h.csv.\n",
      "\n",
      "â³ Fetching data for UNH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully feached and save date of UNH in file path data/raw/ohlcv_data\\UNH_1h.csv.\n",
      "\n",
      "\n",
      "\n",
      "âœ¨ Data fetching complete.\n",
      "ðŸ“ Data saved to the 'data/raw/ohlcv_data' directory.\n"
     ]
    }
   ],
   "source": [
    "# We try model to specilized there prediction on these dedicated tickers\n",
    "tickers = ['AAPL', 'NVDA', 'META', 'TSLA', 'MSFT', 'GOOGL', 'AMZN', 'JPM', 'V', 'UNH']\n",
    "end_date = datetime.now()\n",
    "start_data = end_date - timedelta(days=(2 * 365))\n",
    "\n",
    "output_dir = 'data/raw/ohlcv_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ðŸš€ Fetching historical OHLCV data for {len(tickers)} tickers...\")\n",
    "for ticker in tickers:\n",
    "    print(f'â³ Fetching data for {ticker}')\n",
    "    try:\n",
    "        data = yfinance.download(\n",
    "            ticker,\n",
    "            start=start_data,\n",
    "            end=end_date,\n",
    "            interval='1h',\n",
    "            ignore_tz=True,\n",
    "        )\n",
    "        \n",
    "        if not data.empty:\n",
    "            file_path = os.path.join(output_dir, f'{ticker}_1h.csv')\n",
    "            data.to_csv(file_path)\n",
    "            print(f'âœ… Successfully feached and save date of {ticker} in file path {file_path}.\\n')\n",
    "        else:\n",
    "            print(f'âš ï¸ No data found for {ticker} in the specified data range\\n')\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching data for {ticker}: {e}\\n\")\n",
    "    \n",
    "print(\"\\n\\nâœ¨ Data fetching complete.\")\n",
    "print(f\"ðŸ“ Data saved to the '{output_dir}' directory.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "67fa75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from loading all tickers for cleaning and processing.\n",
    "BASE_PATH = Path(__file__).resolve().parents[2] if '__file__' in globals() else Path.cwd().parents[2]\n",
    "OHLCV_DATA = os.path.join(BASE_PATH, 'data', 'raw', 'ohlcv_data')\n",
    "csv_files = glob.glob(os.path.join(OHLCV_DATA, '*.csv'))\n",
    "\n",
    "ohlcv_data = {}\n",
    "for file in csv_files:\n",
    "    \n",
    "    ticker = Path(file).stem.split('_')[0]\n",
    "    ohlcv_data[ticker] = pd.read_csv(file)\n",
    "    ohlcv_data[ticker] = ohlcv_data[ticker].iloc[2:].reset_index(drop=True)\n",
    "    ohlcv_data[ticker].rename(columns={'Price': 'Datetime'}, inplace=True)\n",
    "    ohlcv_data[ticker]['Datetime'] = pd.to_datetime(ohlcv_data[ticker]['Datetime'])\n",
    "    \n",
    "    for col in ohlcv_data[ticker][ohlcv_data[ticker].columns[1:]]:\n",
    "        try:\n",
    "            ohlcv_data[ticker][col] = ohlcv_data[ticker][col].astype(float)\n",
    "        except ValueError:\n",
    "            ohlcv_data[ticker][col] = ohlcv_data[ticker][col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d3df14bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All DataFrames have the same number (3480) of rows!\n",
      "âœ… No missing values found in any tickers. Data is clean!\n",
      "âœ… No duplicate datetime entries found!\n",
      "ðŸ” Checking for gaps between the rows in each ticker's data...\n",
      "    - AAPL: Largest gap between rows is 3 days 18:00:00\n",
      "    - NVDA: Largest gap between rows is 3 days 18:00:00\n",
      "    - META: Largest gap between rows is 3 days 18:00:00\n",
      "    - TSLA: Largest gap between rows is 3 days 18:00:00\n",
      "    - MSFT: Largest gap between rows is 3 days 18:00:00\n",
      "    - GOOGL: Largest gap between rows is 3 days 18:00:00\n",
      "    - AMZN: Largest gap between rows is 3 days 18:00:00\n",
      "    - JPM: Largest gap between rows is 3 days 18:00:00\n",
      "    - V: Largest gap between rows is 3 days 18:00:00\n",
      "    - UNH: Largest gap between rows is 3 days 18:00:00\n",
      "ðŸš© Flagging Outliers...\n",
      "    âœ… AAPL: No large price changes detected.\n",
      "    âš ï¸ NVDA: Large price change (>20%) detected! ðŸš¨\n",
      "    âœ… META: No large price changes detected.\n",
      "    âœ… TSLA: No large price changes detected.\n",
      "    âœ… MSFT: No large price changes detected.\n",
      "    âœ… GOOGL: No large price changes detected.\n",
      "    âœ… AMZN: No large price changes detected.\n",
      "    âœ… JPM: No large price changes detected.\n",
      "    âœ… V: No large price changes detected.\n",
      "    âš ï¸ UNH: Large price change (>20%) detected! ðŸš¨\n"
     ]
    }
   ],
   "source": [
    "# --- Data Consistency Checks for All Tickers ---\n",
    "\n",
    "# 1. Check if all DataFrames have the same number of rows (to ensure no data mismatch)\n",
    "lengths = [len(ohlcv_data[ticker]) for ticker in tickers]\n",
    "if len(set(lengths)) == 1:\n",
    "    print(f\"âœ… All DataFrames have the same number ({lengths[0]}) of rows!\")\n",
    "else:\n",
    "    print(\"âš ï¸ DataFrames have different number of rows:\", lengths)\n",
    "\n",
    "# 2. Check for missing values in each ticker's DataFrame\n",
    "missing_values = [ohlcv_data[ticker].isna().sum().sum() for ticker in tickers]\n",
    "if len(set(missing_values)) == 1:\n",
    "    print('âœ… No missing values found in any tickers. Data is clean!')\n",
    "else:\n",
    "    print('âš ï¸ Some tickers have missing values. Details:')\n",
    "    for ticker, missing in zip(tickers, missing_values):\n",
    "        if missing > 0:\n",
    "            print(f'   - {ticker}: {missing} missing values')\n",
    "\n",
    "# 3. Check duplicated rows in each ticker's DataFrame\n",
    "any_dupes = False\n",
    "for ticker in tickers:\n",
    "    dupes = ohlcv_data[ticker]['Datetime'].duplicated().sum()\n",
    "    if dupes > 0:\n",
    "        print(f'âš ï¸ {ticker}: {dupes} duplicate datetime entries found!')\n",
    "        any_dupes = True\n",
    "        \n",
    "if not any_dupes:\n",
    "    print('âœ… No duplicate datetime entries found!')\n",
    "    \n",
    "# 4. Check a gaps in between the rows\n",
    "print('ðŸ” Checking for gaps between the rows in each ticker\\'s data...')\n",
    "for ticker in tickers:\n",
    "    idx = ohlcv_data[ticker]['Datetime']\n",
    "    gaps = idx.diff().max()\n",
    "    print(f\"    - {ticker}: Largest gap between rows is {gaps}\")\n",
    "\n",
    "# 5. Flag any ticker that contain outliers\n",
    "print('ðŸš© Flagging Outliers...')\n",
    "for ticker in tickers:\n",
    "    df = ohlcv_data[ticker]\n",
    "    if 'Close' in df.columns:\n",
    "        pct_change = df['Close'].pct_change().abs()\n",
    "        if (pct_change > 0.2).any():\n",
    "            print(f\"    âš ï¸ {ticker}: Large price change (>20%) detected! ðŸš¨\")\n",
    "        else:\n",
    "            print(f\"    âœ… {ticker}: No large price changes detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
